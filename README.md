# selfGuidingBlindApp

## Abstract

### Globally, nearly 90 million individuals live with blindness, facing significant daily challenges in navigating and perceiving their surroundings. To address this, our research presents an intelligent, real-time assistive system that delivers audio-based descriptions of nearby objects and their spatial orientation relative to the user. Utilizing the advanced YOLO v8 model for robust object detection, our system identifies objects within the camera's field of view and communicates their identities and precise locations through Android's Speech Engine. This integration of high-performance detection algorithms with dynamic speech synthesis enhances users' spatial awareness, fostering greater independence and safety. Our approach provides a seamless experience for visually impaired individuals, promoting situational awareness and supporting autonomy in complex environments.
